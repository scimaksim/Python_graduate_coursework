{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d432ff-d11d-49fd-9bf3-14d8d86c1dff",
   "metadata": {},
   "source": [
    "# Assignment 9\n",
    "\n",
    "Maksim Nikiforov"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441954c1-69d9-4f79-90af-0590b8dae9ae",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "In this section we'll look at an example of fitting many models on a data set and choosing the overall best one via test error.\n",
    "\n",
    "Process:\n",
    "1. Read the data in (would then want to explore data, we'll skip this part)\n",
    "2. Split the data into a training and test set\n",
    "3. For each model type, select a **best** model using the training set (we'll use cross-validation but you could split the training set into a training and validation set instead)\n",
    "4. Compare the best models on the test set.  Select the model with the lowest error (with considerations for simplicity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d7b7c-49d1-4335-b123-451dc815845c",
   "metadata": {},
   "source": [
    "## 1. Read in the `diamonds` data set\n",
    "Comes from [kaggle](https://www.kaggle.com/datasets/shivam2503/diamondshttps://www.kaggle.com/datasets/shivam2503/diamonds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6583915f-6b38-4a1a-9ce4-b0b9dd4c2abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "diamonds = pd.read_csv(\"data/diamonds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18edf55a-07f0-4c85-b78c-c580afecd3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'carat', 'cut', 'color', 'clarity', 'depth', 'table',\n",
      "       'price', 'x', 'y', 'z'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat      cut color clarity  depth  table  price     x     y  \\\n",
       "0           1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98   \n",
       "1           2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84   \n",
       "2           3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07   \n",
       "3           4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23   \n",
       "4           5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35   \n",
       "\n",
       "      z  \n",
       "0  2.43  \n",
       "1  2.31  \n",
       "2  2.31  \n",
       "3  2.63  \n",
       "4  2.75  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(diamonds.columns)\n",
    "diamonds.head()\n",
    "\n",
    "# Notice an index column, \"Unnamed: 0\"\n",
    "# We'll remove it and try to predict the price of our diamonds (our response variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a6e585ef-7d14-4529-9168-a491e0994077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop first column\n",
    "diamonds = diamonds.drop(diamonds.columns[0], axis = 1)\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62220a2e-1000-4100-96b5-e0c332f8bb09",
   "metadata": {},
   "source": [
    "Let's use $\\$2401$, the median price of diamonds in this set, as the determinant for \"expensive\" and \"normal\" pricing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d9b14d8c-cb89-4118-bf7d-ed00ef1ecb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2401.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the median price of diamonds\n",
    "diamonds[\"price\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7c2db7-eb15-4957-8659-1c970f689bc5",
   "metadata": {},
   "source": [
    "Diamonds at or below this price point will belong to the \"normal\" (0) price category, and diamonds above $\\$2401$ will be assigned to the \"expensive\" (1) category. Moreover, let's create dummy variables so we can include `cut` and `color`.  We'll remove the `clarity` variable and the continuous `price` variable and use `price_category` as our categorical response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b6dca427-7322-470e-9679-5207ec355ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price_category</th>\n",
       "      <th>Fair</th>\n",
       "      <th>Good</th>\n",
       "      <th>Ideal</th>\n",
       "      <th>Premium</th>\n",
       "      <th>Very Good</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  depth  table     x     y     z  price_category  Fair  Good  Ideal  \\\n",
       "0   0.23   61.5   55.0  3.95  3.98  2.43               0     0     0      1   \n",
       "1   0.21   59.8   61.0  3.89  3.84  2.31               0     0     0      0   \n",
       "2   0.23   56.9   65.0  4.05  4.07  2.31               0     0     1      0   \n",
       "3   0.29   62.4   58.0  4.20  4.23  2.63               0     0     0      0   \n",
       "4   0.31   63.3   58.0  4.34  4.35  2.75               0     0     1      0   \n",
       "\n",
       "   Premium  Very Good  D  E  F  G  H  I  J  \n",
       "0        0          0  0  1  0  0  0  0  0  \n",
       "1        1          0  0  1  0  0  0  0  0  \n",
       "2        0          0  0  1  0  0  0  0  0  \n",
       "3        1          0  0  0  0  0  0  1  0  \n",
       "4        0          0  0  0  0  0  0  0  1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cut_dummies = pd.get_dummies(diamonds.cut)\n",
    "color_dummies = pd.get_dummies(diamonds.color)\n",
    "diamonds[\"price_category\"] = 1\n",
    "diamonds.loc[diamonds[\"price\"] <= diamonds[\"price\"].median(), \"price_category\"] = 0\n",
    "diamonds = diamonds.drop([\"clarity\", \"cut\", \"color\", \"price\"], axis = 1)\n",
    "diamonds = diamonds.join(cut_dummies).join(color_dummies)\n",
    "diamonds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85daeaaa-612f-4a6b-bcbf-b2509727d9e9",
   "metadata": {},
   "source": [
    "Since we're using the median, we'll have roughly half of our diamonds in the \"expensive\" category and half in the \"normal\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "203d9a2f-92ff-4d26-809e-262b19387024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    26985\n",
       "1    26955\n",
       "Name: price_category, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.price_category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3aadb-d943-4ee3-8822-68790a5b1ac8",
   "metadata": {},
   "source": [
    "Now let's check over the data to make sure the dummy variables aren't super rare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb154a96-2a9b-4d3a-828e-debf5c0d53f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price_category</th>\n",
       "      <th>Fair</th>\n",
       "      <th>Good</th>\n",
       "      <th>Ideal</th>\n",
       "      <th>Premium</th>\n",
       "      <th>Very Good</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "      <td>53940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.797940</td>\n",
       "      <td>61.749405</td>\n",
       "      <td>57.457184</td>\n",
       "      <td>5.731157</td>\n",
       "      <td>5.734526</td>\n",
       "      <td>3.538734</td>\n",
       "      <td>0.500204</td>\n",
       "      <td>0.029848</td>\n",
       "      <td>0.090953</td>\n",
       "      <td>0.399537</td>\n",
       "      <td>0.255673</td>\n",
       "      <td>0.223990</td>\n",
       "      <td>0.125603</td>\n",
       "      <td>0.181628</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.209344</td>\n",
       "      <td>0.153949</td>\n",
       "      <td>0.100519</td>\n",
       "      <td>0.052058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.474011</td>\n",
       "      <td>1.432621</td>\n",
       "      <td>2.234491</td>\n",
       "      <td>1.121761</td>\n",
       "      <td>1.142135</td>\n",
       "      <td>0.705699</td>\n",
       "      <td>0.500005</td>\n",
       "      <td>0.170169</td>\n",
       "      <td>0.287545</td>\n",
       "      <td>0.489808</td>\n",
       "      <td>0.436243</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>0.331404</td>\n",
       "      <td>0.385541</td>\n",
       "      <td>0.381588</td>\n",
       "      <td>0.406844</td>\n",
       "      <td>0.360903</td>\n",
       "      <td>0.300694</td>\n",
       "      <td>0.222146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>4.710000</td>\n",
       "      <td>4.720000</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.040000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>6.540000</td>\n",
       "      <td>4.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.010000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>10.740000</td>\n",
       "      <td>58.900000</td>\n",
       "      <td>31.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat         depth         table             x             y  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.797940     61.749405     57.457184      5.731157      5.734526   \n",
       "std        0.474011      1.432621      2.234491      1.121761      1.142135   \n",
       "min        0.200000     43.000000     43.000000      0.000000      0.000000   \n",
       "25%        0.400000     61.000000     56.000000      4.710000      4.720000   \n",
       "50%        0.700000     61.800000     57.000000      5.700000      5.710000   \n",
       "75%        1.040000     62.500000     59.000000      6.540000      6.540000   \n",
       "max        5.010000     79.000000     95.000000     10.740000     58.900000   \n",
       "\n",
       "                  z  price_category          Fair          Good         Ideal  \\\n",
       "count  53940.000000    53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       3.538734        0.500204      0.029848      0.090953      0.399537   \n",
       "std        0.705699        0.500005      0.170169      0.287545      0.489808   \n",
       "min        0.000000        0.000000      0.000000      0.000000      0.000000   \n",
       "25%        2.910000        0.000000      0.000000      0.000000      0.000000   \n",
       "50%        3.530000        1.000000      0.000000      0.000000      0.000000   \n",
       "75%        4.040000        1.000000      0.000000      0.000000      1.000000   \n",
       "max       31.800000        1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "            Premium     Very Good             D             E             F  \\\n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  53940.000000   \n",
       "mean       0.255673      0.223990      0.125603      0.181628      0.176900   \n",
       "std        0.436243      0.416919      0.331404      0.385541      0.381588   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                  G             H             I             J  \n",
       "count  53940.000000  53940.000000  53940.000000  53940.000000  \n",
       "mean       0.209344      0.153949      0.100519      0.052058  \n",
       "std        0.406844      0.360903      0.300694      0.222146  \n",
       "min        0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamonds.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f3f39-f4dc-41ec-a900-56de88c0adc5",
   "metadata": {},
   "source": [
    "Note: ideally we would explore the data more and consider transformations of variables and other feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5ac68-333c-4cd1-a574-419af1fe820d",
   "metadata": {},
   "source": [
    "## 2. Training and Test Split\n",
    "First, let's just read in all the functions we'll need from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b015ed62-8290-4c6a-a6d2-e6e3d4c6a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bc846b-a2c5-4acb-abcc-8c39e7518ed8",
   "metadata": {},
   "source": [
    "We can then separate our data into train (80%) and test (20%) sets. Our response column will be `price_category`, and the remaining columns will constitute our potential predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c9ef5d9-396e-43ed-8df8-9d801754846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 80/20 split for our train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "  diamonds.drop(\"price_category\", axis = 1), # x variables (predictors)\n",
    "  diamonds[\"price_category\"],                # y variable (response)\n",
    "  test_size=0.20, \n",
    "  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbdb1a8-5500-47a3-b1c8-eada39d2803d",
   "metadata": {},
   "source": [
    "## 3. Fit and Select Models on Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21a11f-feb7-4ed2-a36c-7c3f2ac356b3",
   "metadata": {},
   "source": [
    "### Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296f64b4-70db-448d-97df-9c3f76b5ae2e",
   "metadata": {},
   "source": [
    "Now, we can fit a series of logistic regression models. \n",
    "\n",
    "- `cv_full_model` uses the entire training set (all of our predictors)\n",
    "- `cv_numeric_model` includes all of our numeric predictors (no dummy variables)\n",
    "- `cv_dummy_model` uses only the dummy variables\n",
    "- `cv_full_interaction_model` creates interaction terms but does not standardize variables\n",
    "- `cv_numeric_interaction_model` - numeric-variable-only interaction model with categorical variables\n",
    "\n",
    "We use 5-fold cross-validation and _accuracy_ as our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c525f32c-66f6-4e8b-8315-08abbf08bbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model (entire training set)\n",
    "cv_full_model = cross_validate(\n",
    "    LogisticRegression(penalty = \"none\", max_iter = 10000, solver = \"lbfgs\"), \n",
    "    X = X_train, \n",
    "    y = y_train, \n",
    "    cv = 5)\n",
    "\n",
    "# Numeric variables only (no dummy variables)\n",
    "cv_numeric_model = cross_validate( \n",
    "    LogisticRegression(penalty = \"none\", max_iter = 10000, solver = \"lbfgs\"), \n",
    "    X = X_train[[\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]], \n",
    "    y = y_train, \n",
    "    cv = 5)\n",
    "\n",
    "# Use only dummy variables (columns 8 and beyond)\n",
    "cv_dummy_model = cross_validate(     # only use our dummy variables\n",
    "    LogisticRegression(penalty = \"none\", max_iter = 10000, solver = \"lbfgs\"), \n",
    "    X_train.iloc[:, 8:], \n",
    "    y_train, \n",
    "    cv = 5)\n",
    "\n",
    "# Use PolynomialFeatures to create interaction terms, do not standardize variables first\n",
    "poly = PolynomialFeatures(interaction_only=True, include_bias = False)  \n",
    "\n",
    "# Full a full interaction model \n",
    "cv_full_interaction_model = cross_validate(\n",
    "    LogisticRegression(penalty = \"none\", max_iter = 10000, solver = \"lbfgs\"), \n",
    "    poly.fit_transform(X_train), # fit all 1-way (first-order) interactions between our variables\n",
    "    y_train, \n",
    "    cv = 5)\n",
    "\n",
    "# Numeric-variable-only interaction model with categorical variables (columns 8 and beyond)\n",
    "cv_numeric_interaction_model = cross_validate(\n",
    "    LogisticRegression(penalty = \"none\", max_iter = 10000, solver = \"lbfgs\"), \n",
    "    np.concatenate((poly.fit_transform(X_train[[\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]]), X_train.iloc[:, 8:].to_numpy()), axis = 1), \n",
    "    y_train, \n",
    "    cv = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f331122-6fc4-42ad-8fc7-9fb52720ff27",
   "metadata": {},
   "source": [
    "`cv_full_model`, `cv_numeric_model`, `cv_dummy_model`, `cv_full_interaction_model`, and `cv_numeric_interaction_model` all have the output of the `cross_validate` function for test scores. They were accuracy measures for each fold, and we want to combine them. We can do this by just finding the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0eaf320f-3ce0-465d-85d7-84845a0e6413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96176573 0.96025953 0.9603708  0.96280417 0.9612978 ] [0.94913683 0.94902097 0.94623407 0.95005794 0.95086906] [0.58382574 0.59309466 0.58667439 0.5801854  0.5783314 ] [0.96037539 0.95991195 0.96245655 0.96152955 0.96118192] [0.96199745 0.96025953 0.95886443 0.96257242 0.96095017]\n"
     ]
    }
   ],
   "source": [
    "print(cv_full_model['test_score'], \n",
    "      cv_numeric_model['test_score'], \n",
    "      cv_dummy_model['test_score'], \n",
    "      cv_full_interaction_model['test_score'], \n",
    "      cv_numeric_interaction_model['test_score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8581d9b7-4ce0-4a69-9402-02ec191d54a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9613, 0.9491, 0.5844, 0.9611, 0.9609]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find average accuracies for each model\n",
    "[round(cv_full_model['test_score'].mean(),4), \n",
    " round(cv_numeric_model['test_score'].mean(),4), \n",
    " round(cv_dummy_model['test_score'].mean(),4),\n",
    " round(cv_full_interaction_model['test_score'].mean(),4), \n",
    " round(cv_numeric_interaction_model['test_score'].mean(),4),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8e021d-a0ce-44f4-acdd-d2847f1062e9",
   "metadata": {},
   "source": [
    "`cv_full_model` appears to have the highest average accuracy at 0.9613, but it's nearly identical to the accuracy of `cv_full_interaction_model` and `cv_numeric_interaction_model`. We'll use `cv_full_model` as our \"best\" model, since it is the simplest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "febda456-7e0b-46cf-be66-92b3780fced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg_best = LogisticRegression(penalty = \"none\", max_iter = 10000, solver = \"lbfgs\").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e5503-cf3c-4ae3-9a29-e011184f45bc",
   "metadata": {},
   "source": [
    "### Classification Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c808485-c139-4d9c-aad3-0a3828b1c5fb",
   "metadata": {},
   "source": [
    "We can use a `DecisionTreeClassifier` to fit classification trees, and use accuracy as our loss function.\n",
    "\n",
    "Sometimes we want to fit a tree, but it ends up being overfitted. We can **prune** trees in a few ways, including cost-complexity pruning or cross-validation. We can also control the minimum number of samples that a leaf can have (`min_sample_leaf`), among other things.\n",
    "\n",
    "The best combination can be determined using cross-validation, where we\n",
    "\n",
    "1. Set up the values to consider (our tuning `parameters`)\n",
    "2. Use `GridSearchCV()` to return the best values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cbf913e8-6ad7-419a-93a0-cafbaad47ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': range(2,20), # how many splits we'll do\n",
    "              'min_samples_leaf':[10, 50, 100, 250]}\n",
    "tree_model = GridSearchCV(DecisionTreeClassifier(), # the model to use\n",
    "                            parameters, \n",
    "                            cv = 5, \n",
    "                            scoring='accuracy') \\\n",
    "                          .fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56def65e-067c-443a-b162-8085d8c7894f",
   "metadata": {},
   "source": [
    "The optimal combination of parameters appears to be `max_depth=7` and `min_samples_leaf=10`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "293ee2f8-8baa-4d44-9f5f-c53408528928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=7, min_samples_leaf=10)\n"
     ]
    }
   ],
   "source": [
    "print(tree_model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "86c5f16b-6fb6-4a70-b772-eab3905211d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9599554893413526 {'max_depth': 7, 'min_samples_leaf': 10}\n"
     ]
    }
   ],
   "source": [
    "# best_score_ is accuracy for the \"best\" model\n",
    "print(tree_model.best_score_, tree_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fac1105-3ff0-42a1-a791-fbc05b3dcde8",
   "metadata": {},
   "source": [
    "We can use the `cross_validate` function to see the accuracies four our model using the optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cfa89af-ea45-4bff-a154-20f82ff42984",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctree_cv = cross_validate(tree_model.best_estimator_,\n",
    "                          X_train,\n",
    "                          y_train,\n",
    "                          cv = 5,\n",
    "                          scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5ee582cc-e818-430f-b802-cef8d9d4fb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95968022 0.9609547  0.95793743 0.96141367 0.95979143]\n"
     ]
    }
   ],
   "source": [
    "print(ctree_cv['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4552508-2ac2-4f4f-b034-c07c34c7d1ab",
   "metadata": {},
   "source": [
    "We can save the model with the best estimator (`max_depth=7` and `min_samples_leaf=10`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "235921fa-71af-4fe5-9149-2d7f88511f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctree_best = tree_model.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef287d1-234d-4e03-b644-7d126a2d2dbb",
   "metadata": {},
   "source": [
    "### Random Forest Model (Includes Bagged Tree as a Special Case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0036133-bc1c-4227-8be9-df09d6b32b8b",
   "metadata": {},
   "source": [
    "Random forests use the same idea as bagging, but we don't use all predictors in each tree. Instead, we only use a random subset of predictors for each bootstrap sample/tree fit. Why? If we have a very strong predictor in our data set, every first split will split on that best variable. This makes bagged trees more correlated to one another. But using a random subset of predictors, we get less correlated trees, which in turn reduces variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74a4e0e9-d379-45b5-a994-b6f50a2b6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': range(2,20), # how many splits we'll do\n",
    "              'min_samples_leaf':[10, 50, 100, 250]}\n",
    "rf_tune = GridSearchCV(RandomForestClassifier(),\n",
    "                          parameters,\n",
    "                          cv = 5) \\\n",
    "                          .fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a9df49b-75c2-4692-a6b0-68166b72c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=13, min_samples_leaf=10)\n"
     ]
    }
   ],
   "source": [
    "print(rf_tune.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56367ec2-736e-4558-852f-0101890e5869",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv = cross_validate(rf_tune.best_estimator_,\n",
    "                       X_train,\n",
    "                       y_train,\n",
    "                       cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea5f2c58-0011-402b-98b6-421e010afc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.96083884 0.96141814 0.96071842 0.96373117 0.9617613 ]\n"
     ]
    }
   ],
   "source": [
    "print(rf_cv['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "953e16c8-a3f1-45b7-9b16-d0b3cf7bde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = rf_tune.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea52e0-e14d-410f-8ae9-01ce504cf91e",
   "metadata": {},
   "source": [
    "## 4. Compare on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138d33f-3863-496f-a18c-a144e553e0f0",
   "metadata": {},
   "source": [
    "We can compare the accuracy across all of our \"best\" models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "06fd73f6-e166-43ff-8c62-f08d9c3573c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9618094178717093 0.9591212458286985 0.9616240266963293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "logistic_pred = logistic_reg_best.predict(X_test)\n",
    "ctree_pred = ctree_best.predict(X_test)\n",
    "rf_pred = rf_best.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, logistic_pred), accuracy_score(y_test, ctree_pred), accuracy_score(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231f5747-bb3b-45dc-9295-3027536263bd",
   "metadata": {},
   "source": [
    "We get an accuracy in the range of 95.9%-96.2%. The logistic regression model is best with an accuracy of 96.18%, slightly beating our random forest model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae19fb36-45ea-48e3-8a79-66cc4fbf146c",
   "metadata": {},
   "source": [
    "## 5. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d8dc17c-2cbc-4827-aa04-b9790dbb8f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5160,  241],\n",
       "       [ 173, 5214]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, rf_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935382a-34bc-478f-9129-8b5859a08d15",
   "metadata": {},
   "source": [
    "The confusion matrix shows 5160 true negatives in the top left, 241 false positives in the top right, 173 false negatives in the lower left, and 5214 true positives in the lower right. "
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
